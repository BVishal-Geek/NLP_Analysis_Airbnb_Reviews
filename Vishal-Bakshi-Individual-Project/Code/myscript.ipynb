{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e537872-6200-4256-b8de-13c6f8e82c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FinalSummerization.py\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "# Load data and prompt user for listing ID\n",
    "csv_file_path = 'processed_reviews_SentimentLabels.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "listing_id = int(input(\"Please enter the listing_id to summarize reviews for: \"))\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = 't5-large'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def chunk_text(text, tokenizer, chunk_size=512):\n",
    "    \"\"\"\n",
    "    Split a long text into smaller chunks based on tokenized length.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to be chunked.\n",
    "        tokenizer (T5Tokenizer): Tokenizer for encoding the text.\n",
    "        chunk_size (int): Maximum number of tokens per chunk.\n",
    "\n",
    "    Returns:\n",
    "        list[torch.Tensor]: A list of tokenized chunks.\n",
    "    \"\"\"\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\")[0]\n",
    "    return [tokenized_text[i:i + chunk_size] for i in range(0, len(tokenized_text), chunk_size)]\n",
    "\n",
    "\n",
    "def summarize_chunk(chunk, tokenizer, model, device, chunk_max_length=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Generate a summary for a single chunk of text.\n",
    "\n",
    "    Args:\n",
    "        chunk (torch.Tensor): Tokenized chunk of text.\n",
    "        tokenizer (T5Tokenizer): Tokenizer for decoding and preparing input.\n",
    "        model (T5ForConditionalGeneration): Pre-trained T5 model for summarization.\n",
    "        device (torch.device): Device to execute the model on (CPU/GPU).\n",
    "        chunk_max_length (int): Maximum length of the summary.\n",
    "        verbose (bool): Whether to print detailed logs.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated summary for the chunk.\n",
    "    \"\"\"\n",
    "    chunk_text_decoded = tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "    input_text = \"summarize: \" + chunk_text_decoded\n",
    "    tokenized_text = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        tokenized_text,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        min_length=30,\n",
    "        max_length=chunk_max_length,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    chunk_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[CHUNK INPUT]: {input_text[:300]}...\")\n",
    "        print(f\"[CHUNK SUMMARY]: {chunk_summary}\")\n",
    "\n",
    "    return chunk_summary\n",
    "\n",
    "\n",
    "def summarize_large_text(text, tokenizer, model, device, chunk_size=512, chunk_max_length=100,\n",
    "                         final_min_length=100, final_max_length=200, verbose=True):\n",
    "    \"\"\"\n",
    "    Summarize a large text by breaking it into chunks, summarizing each, and combining the results.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to be summarized.\n",
    "        tokenizer (T5Tokenizer): Tokenizer for encoding and decoding.\n",
    "        model (T5ForConditionalGeneration): Pre-trained T5 model for summarization.\n",
    "        device (torch.device): Device to execute the model on (CPU/GPU).\n",
    "        chunk_size (int): Maximum token size for each chunk.\n",
    "        chunk_max_length (int): Maximum length for each chunk's summary.\n",
    "        final_min_length (int): Minimum length for the final summary.\n",
    "        final_max_length (int): Maximum length for the final summary.\n",
    "        verbose (bool): Whether to print detailed logs.\n",
    "\n",
    "    Returns:\n",
    "        str: Final comprehensive summary.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\nSplitting text into chunks...\")\n",
    "    chunks = chunk_text(text, tokenizer, chunk_size)\n",
    "    if verbose:\n",
    "        print(f\"Total chunks created: {len(chunks)}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nSummarizing individual chunks...\")\n",
    "    chunk_summaries = []\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        if verbose:\n",
    "            print(f\"\\nSummarizing chunk {i}/{len(chunks)}\")\n",
    "        chunk_summary = summarize_chunk(chunk, tokenizer, model, device, chunk_max_length, verbose=verbose)\n",
    "        chunk_summaries.append(chunk_summary)\n",
    "\n",
    "    combined_summary_text = \" \".join(chunk_summaries)\n",
    "\n",
    "    final_input_text = (\n",
    "            \"summarize: Provide a detailed and coherent summary of guest reviews, \"\n",
    "            \"highlighting themes about the host's personality, accommodation quality, neighborhood vibe, \"\n",
    "            \"safety, and accessibility to transportation. \" + combined_summary_text\n",
    "    )\n",
    "\n",
    "    tokenized_summary = tokenizer.encode(final_input_text, return_tensors=\"pt\").to(device)\n",
    "    if verbose:\n",
    "        print(\"\\nGenerating final summary...\")\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        tokenized_summary,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        min_length=final_min_length,\n",
    "        max_length=final_max_length,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def summarize_reviews_for_listing(listing_id, verbose=True):\n",
    "    \"\"\"\n",
    "    Summarize all reviews associated with a given listing ID.\n",
    "\n",
    "    Args:\n",
    "        listing_id (int): ID of the listing to summarize reviews for.\n",
    "        verbose (bool): Whether to print detailed progress and logs.\n",
    "\n",
    "    Returns:\n",
    "        str: Final summary of reviews for the listing ID.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\nRetrieving reviews for listing_id {listing_id}...\")\n",
    "    reviews = data[data['listing_id'] == listing_id]['review']\n",
    "    if reviews.empty:\n",
    "        return f\"No reviews found for listing_id {listing_id}\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nSample reviews:\")\n",
    "        for idx, review in enumerate(reviews.head(3), start=1):\n",
    "            print(f\"[Sample Review {idx}]: {review}\")\n",
    "\n",
    "    combined_reviews = \" \".join(reviews)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nSummarizing all reviews...\")\n",
    "    return summarize_large_text(\n",
    "        combined_reviews,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        device,\n",
    "        chunk_size=512,\n",
    "        chunk_max_length=100,\n",
    "        final_min_length=100,\n",
    "        final_max_length=200,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "\n",
    "# Execute the summarization\n",
    "final_summary = summarize_reviews_for_listing(listing_id, verbose=True)\n",
    "print(f\"\\nFINAL SUMMARY for listing_id {listing_id}:\\n{final_summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd4e8a-52bf-4ef4-b880-0955329a7da6",
   "metadata": {},
   "source": [
    "## Review Summary for Listing ID: 10452\n",
    "\n",
    "### Retrieving Reviews\n",
    "**Listing ID:** 10452\n",
    "\n",
    "**Status:** Retrieving reviews...\n",
    "\n",
    "### Sample Reviews\n",
    "1. **Sample Review 1:**  \n",
    "   Angela was a great host. Great location. Spacious bedroom with comfortable bed. Very good value. Enjoyed my stay!\n",
    "\n",
    "2. **Sample Review 2:**  \n",
    "   I’ve stayed in a bunch of Airbnbs and Angela was by far one of the best hosts. She kept the place super clean and even offered to take care of the laundry throughout my stay. She responded within 5 mins of me needing anything. She was happy and always willing to go above and beyond for anything I needed. She’s a sweetheart and she made it feel like it was my own home. Definitely recommend this place to anyone.\n",
    "\n",
    "3. **Sample Review 3:**  \n",
    "   Great location! We loved staying in Crown Heights. There were wonderful coffee shops and restaurants nearby. The room we were given was not exactly the one pictured but it was fine. Angela was amazing!  \n",
    "\n",
    "### Summarizing All Reviews\n",
    "- **Process:**\n",
    "  - Splitting text into chunks...\n",
    "  - **Total Chunks Created:** 12\n",
    "\n",
    "- **Summarizing Individual Chunks:**\n",
    "  - **Chunk 1/12**\n",
    "    - **Input:**  \n",
    "      Angela was a great host. Great location. Spacious bedroom with comfortable bed. Very good value. Enjoyed my stay! I’ve stayed in a bunch of Airbnbs and Angela was by far one of the best hosts. She kept the place super clean and even offered to take care of the laundry throughout my stay....\n",
    "    - **Summary:**  \n",
    "      Angela is a lovely host. She keeps the place clean, responds to messages quickly, and goes out of her way to make sure her guests have everything they need. The neighborhood was wonderful, I felt very safe. The subway was a 4-minute walk from the apartment!\n",
    "\n",
    "    <!-- Repeat similar formatting for chunks 2-12 -->\n",
    "\n",
    "### **Final Summary for Listing ID 10452**\n",
    "\n",
    "**Angela is a lovely host. She keeps the place clean, responds to messages quickly, and goes out of her way to make sure her guests have everything they need. For $50/night, it's not a terrible value. The location is good, with plenty of stores, bars, and a train station really close that can get you to Manhattan in 15 minutes. I spent one month at Angela's and to be honest, it was great. She is always available and ready to help you in any matter.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7858c2-f4d2-4851-ab6f-4f0913baf80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABSA_plots.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'AspectbasedSentimentAnalysis.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n",
    "\n",
    "\n",
    "# Filter the dataset for the given listing_id and aspect \"Value and Pricing\"\n",
    "filtered_data_value_pricing = data[(data['listing_id'] == 1217318) & \n",
    "                                   (data['aspects'] == 'Value and Pricing')]\n",
    "\n",
    "# Convert the 'review_posted_date' column to datetime for proper sorting and plotting\n",
    "filtered_data_value_pricing['review_posted_date'] = pd.to_datetime(filtered_data_value_pricing['review_posted_date'])\n",
    "\n",
    "# Group data by date and sentiment to see the evolution over time\n",
    "evolution_data_value_pricing = filtered_data_value_pricing.groupby(['review_posted_date', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Prepare data for stacked area plot\n",
    "evolution_data_value_pricing_cumsum = evolution_data_value_pricing.cumsum()\n",
    "\n",
    "# Plotting a stacked area chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stackplot(evolution_data_value_pricing_cumsum.index, \n",
    "              evolution_data_value_pricing_cumsum[0], \n",
    "              evolution_data_value_pricing_cumsum[1], \n",
    "              labels=['Negative', 'Positive'], alpha=0.7)\n",
    "plt.title(\"Cumulative Evolution of 'Value and Pricing' Aspect for Listing ID 1217318\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Count of Reviews\")\n",
    "plt.legend(title=\"Sentiment Label\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8f9d7-4b99-4cf7-bc64-e37fa8d4f2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
